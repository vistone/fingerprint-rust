# Phase 7.2 æ‰§è¡Œè®¡åˆ’ - æ•°æ®é›†æ„å»ºä¸ç‰¹å¾å·¥ç¨‹

## ç›®æ ‡å’ŒèŒƒå›´

**ä¸»è¦ç›®æ ‡**: æ„å»º990ä¸ªæ ·æœ¬çš„é«˜è´¨é‡MLè®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…å«50+ç‰¹å¾ç»´åº¦

**æ•°æ®é›†è§„æ¨¡**:
- æµè§ˆå™¨é…ç½®æ•°: 66ä¸ª
- æ ·æœ¬æ€»æ•°: 990ä¸ª (15æ ·æœ¬/é…ç½®)
- ç‰¹å¾ç»´åº¦: 50+
- æ ‡ç­¾å±‚çº§: 3çº§ (family â†’ version â†’ patch)

---

## åˆ†é˜¶æ®µæ‰§è¡Œè®¡åˆ’

### Stage 1: æ•°æ®é‡‡æ ·ä¸æ‰©å…… (2å°æ—¶)

**ç›®æ ‡**: ä»66ä¸ªå·²æœ‰é…ç½®ç”Ÿæˆ990ä¸ªå˜å¼‚æ ·æœ¬

**æ­¥éª¤**:
1. **åŸºç¡€é‡‡æ ·** (1å°æ—¶)
   - ä¸ºæ¯ä¸ªé…ç½®ç”Ÿæˆ5ä¸ªGREASEå˜ä½“
   - å¯¹æ¯ä¸ªå˜ä½“åˆ›å»º3ä¸ªä¼šè¯
   - æ€»è®¡: 66 Ã— 5 Ã— 3 = 990ä¸ªæ ·æœ¬

2. **å˜å¼‚ç­–ç•¥** (1å°æ—¶)
   - GREASEå€¼éšæœºåŒ– (GREASEæ‰©å±•ä¸­çš„éšæœºå€¼)
   - å¯†ç å¥—ä»¶é¡ºåºéšæœºæ‰“ä¹±
   - æ‰©å±•é¡ºåºéšæœºé‡æ’
   - ä¼ªé€ HTTP headerå˜ä½“

**è¾“å‡º**:
- `dataset/raw_samples/` (990ä¸ªJSONæ ·æœ¬)
- `dataset/sample_manifest.csv` (æ ·æœ¬ç´¢å¼•)

---

### Stage 2: ç‰¹å¾æå– (3å°æ—¶)

**ç›®æ ‡**: ä»990ä¸ªæ ·æœ¬ä¸­æå–50+ç»´åº¦ç‰¹å¾

**ç‰¹å¾åˆ†ç±»**:

#### A. TLSåŸºç¡€ç‰¹å¾ (12ç»´)
- tls_version (TLS 1.2 / 1.3)
- num_cipher_suites (å¯†ç å¥—ä»¶æ•°é‡)
- num_extensions (æ‰©å±•æ•°é‡)
- num_curves (æ”¯æŒæ›²çº¿æ•°)
- num_signature_algs (ç­¾åç®—æ³•æ•°)
- has_alpn (æ˜¯å¦æ”¯æŒALPN)
- has_session_ticket (æ˜¯å¦æ”¯æŒSessionTicket)
- has_supported_groups (æ˜¯å¦æ”¯æŒSupportedGroups)
- has_key_share (æ˜¯å¦æ”¯æŒKeyShare)
- has_psk (æ˜¯å¦æ”¯æŒPSK)
- has_early_data (æ˜¯å¦æ”¯æŒEarlyData)
- max_fragment_length

#### B. å¯†ç å¥—ä»¶ç‰¹å¾ (8ç»´)
- cipher_suite_hash (å¯†ç å¥—ä»¶é›†åˆå“ˆå¸Œ)
- top_cipher_1 (æœ€å¸¸è§å¯†ç å¥—ä»¶ç±»å‹)
- top_cipher_2 (ç¬¬äºŒå¸¸è§)
- has_aes_gcm (æ˜¯å¦åŒ…å«AES-GCM)
- has_chacha (æ˜¯å¦åŒ…å«ChaCha20)
- has_ecdhe_ecdsa (æ˜¯å¦ECDHE-ECDSA)
- has_ecdhe_rsa (æ˜¯å¦ECDHE-RSA)
- has_rsa_pss (æ˜¯å¦RSA-PSS)

#### C. æ‰©å±•ç›¸å…³ç‰¹å¾ (10ç»´)
- extension_set_hash (æ‰©å±•é›†åˆå“ˆå¸Œ)
- extension_order_hash (æ‰©å±•é¡ºåºå“ˆå¸Œ)
- has_grease (æ˜¯å¦åŒ…å«GREASE)
- grease_count (GREASEæ‰©å±•ä¸ªæ•°)
- grease_positions (GREASEä½ç½®ç¼–ç )
- supported_versions_hash (æ”¯æŒç‰ˆæœ¬é›†åˆå“ˆå¸Œ)
- has_sni (æ˜¯å¦SNI)
- has_padding (æ˜¯å¦Paddingæ‰©å±•)
- has_ech (æ˜¯å¦ECH)
- has_app_layer_proto_nego (æ˜¯å¦ALPN/NPN)

#### D. æ›²çº¿ä¸ç­¾åç‰¹å¾ (8ç»´)
- curve_set_hash (æ›²çº¿é›†åˆå“ˆå¸Œ)
- has_x25519 (æ˜¯å¦X25519)
- has_secp256r1 (æ˜¯å¦P-256)
- has_secp384r1 (æ˜¯å¦P-384)
- sig_alg_set_hash (ç­¾åç®—æ³•é›†åˆå“ˆå¸Œ)
- sig_alg_ecdsa_sha256 (æ˜¯å¦ECDSA-SHA256)
- sig_alg_ecdsa_sha384 (æ˜¯å¦ECDSA-SHA384)
- sig_alg_rsa_pss_sha256 (æ˜¯å¦RSA-PSS-SHA256)

#### E. ç‰ˆæœ¬æ ‡è¯†ç‰¹å¾ (8ç»´)
- browser_family (æµè§ˆå™¨æ—ç¾¤ID: 0-10)
- browser_major_version (ä¸»ç‰ˆæœ¬å·)
- browser_minor_version (æ¬¡ç‰ˆæœ¬å·)
- browser_patch_version (è¡¥ä¸ç‰ˆæœ¬å·)
- is_psk_variant (æ˜¯å¦PSKå˜ä½“)
- is_pq_variant (æ˜¯å¦PQå˜ä½“)
- os_type (æ“ä½œç³»ç»Ÿ: 0=Windows, 1=Mac, 2=Linux, 3=iOS, 4=Android)
- device_type (è®¾å¤‡ç±»å‹: 0=Desktop, 1=Mobile, 2=SDK)

#### F. HTTPç‰¹å¾ (6ç»´)
- ua_browser_type (UAå­—ç¬¦ä¸²ä¸­çš„æµè§ˆå™¨ç±»å‹)
- ua_os_type (UAå­—ç¬¦ä¸²ä¸­çš„OS)
- ua_version_presence (UAä¸­æ˜¯å¦åŒ…å«ç‰ˆæœ¬å·)
- http2_pseudo_header_order (HTTP/2ä¼ªå¤´é¡ºåº)
- http2_regular_header_order (å¸¸è§„å¤´éƒ¨é¡ºåºå“ˆå¸Œ)
- accept_language_count (Accept-Languageæ•°é‡)

**è¾“å‡º**:
- `dataset/features.csv` (990è¡Œ Ã— 52åˆ—)
- `dataset/feature_metadata.json` (ç‰¹å¾è¯¦ç»†è¯´æ˜)

---

### Stage 3: æ ‡ç­¾åŒ–ä¸æ•°æ®éªŒè¯ (2å°æ—¶)

**ç›®æ ‡**: æ·»åŠ å‡†ç¡®çš„æ ‡ç­¾ï¼ŒéªŒè¯æ•°æ®è´¨é‡

**æ ‡ç­¾ç»“æ„**:

| åˆ—å | ç±»å‹ | èŒƒå›´ | è¯´æ˜ |
|------|------|------|------|
| label_family | categorical | 0-10 | chrome, firefox, safariç­‰ |
| label_version | categorical | 0-255 | ä¸»ç‰ˆæœ¬å· |
| label_patch | categorical | 0-255 | è¡¥ä¸ç‰ˆæœ¬å· |
| label_variant | categorical | 0-2 | 0=standard, 1=PSK, 2=PQ |
| sample_id | string | - | æ ·æœ¬å”¯ä¸€ID |
| source_config | string | - | æºé…ç½®æ–‡ä»¶ |
| grease_variant | int | 0-5 | GREASEå˜ä½“åºå· |
| session_id | int | 0-2 | ä¼šè¯åºå· |

**æ•°æ®éªŒè¯**:
- âœ“ æ ‡ç­¾å®Œæ•´æ€§æ£€æŸ¥ (æ— ç¼ºå¤±)
- âœ“ åˆ†å¸ƒå‡åŒ€æ€§æ£€æŸ¥ (å„æ—ç¾¤å‡è¡¡)
- âœ“ ç‰¹å¾å¼‚å¸¸æ£€æµ‹
- âœ“ é‡å¤æ ·æœ¬æ£€æµ‹

**è¾“å‡º**:
- `dataset/labels.csv` (æ ·æœ¬æ ‡ç­¾)
- `dataset/validation_report.md` (è´¨é‡æ£€æŸ¥æŠ¥å‘Š)

---

### Stage 4: æ•°æ®é›†æ•´åˆä¸æ‰“åŒ… (1å°æ—¶)

**ç›®æ ‡**: ç”Ÿæˆæœ€ç»ˆçš„MLè®­ç»ƒæ•°æ®é›†

**æ–‡ä»¶ç»“æ„**:
```
dataset/
â”œâ”€â”€ 20260213_ml_training_dataset.csv (å®Œæ•´990è¡Œ)
â”œâ”€â”€ train_set.csv (791è¡Œ, 80%)
â”œâ”€â”€ val_set.csv (99è¡Œ, 10%)
â”œâ”€â”€ test_set.csv (99è¡Œ, 10%)
â”œâ”€â”€ metadata.json (æ•°æ®é›†å…ƒæ•°æ®)
â”œâ”€â”€ feature_schema.json (ç‰¹å¾å®šä¹‰)
â””â”€â”€ README.md (ä½¿ç”¨è¯´æ˜)
```

**æ•°æ®åˆ†å‰²ç­–ç•¥**:
- è®­ç»ƒé›† (80%, 792æ ·æœ¬): ç”¨äºæ¨¡å‹è®­ç»ƒ
- éªŒè¯é›† (10%, 99æ ·æœ¬): ç”¨äºè¶…å‚æ•°è°ƒä¼˜
- æµ‹è¯•é›† (10%, 99æ ·æœ¬): ç”¨äºæœ€ç»ˆè¯„ä¼°

**å…ƒæ•°æ®åŒ…å«**:
- ç‰¹å¾åˆ—è¡¨å’Œç±»å‹
- æ ‡ç­¾ç¼–ç æ˜ å°„
- ç»Ÿè®¡æ±‡æ€» (å‡å€¼/æ–¹å·®/åˆ†å¸ƒ)
- æ•°æ®è´¨é‡æŒ‡æ ‡

---

## è¯¦ç»†å®ç°æ­¥éª¤

### Step 1: åˆ›å»ºæ ·æœ¬ç”Ÿæˆè„šæœ¬

**æ–‡ä»¶**: `scripts/generate_ml_dataset.py`

```python
# ä¼ªä»£ç 
import json
import os
from pathlib import Path
import pandas as pd
import numpy as np

def generate_samples():
    """ç”Ÿæˆ990ä¸ªå˜å¼‚æ ·æœ¬"""
    samples = []
    
    for config_file in sorted(Path("exported_profiles").glob("*.json")):
        config = load_json(config_file)
        
        # ä¸ºæ¯ä¸ªé…ç½®ç”Ÿæˆ5ä¸ªGREASEå˜ä½“
        for grease_idx in range(5):
            # ä¸ºæ¯ä¸ªå˜ä½“ç”Ÿæˆ3ä¸ªä¼šè¯
            for session_idx in range(3):
                sample = {
                    'source_config': config_file.stem,
                    'grease_variant': grease_idx,
                    'session_id': session_idx,
                    'tls_config': apply_variations(config, grease_idx),
                    'http_headers': generate_http_headers(config),
                }
                samples.append(sample)
    
    return samples

def apply_variations(config, grease_idx):
    """åº”ç”¨GREASEå’Œå…¶ä»–å˜å¼‚"""
    varied = copy.deepcopy(config)
    
    # 1. éšæœºåŒ–GREASEå€¼
    for ext in varied['extensions']:
        if ext['type'] == 'GREASE':
            ext['data'] = random_grease_value(grease_idx)
    
    # 2. éšæœºåŒ–å¯†ç å¥—ä»¶é¡ºåº (ä¿ç•™å‰3ä¸ª)
    np.random.shuffle(varied['cipher_suites'][3:])
    
    # 3. éšæœºåŒ–æ‰©å±•é¡ºåº (ä¿ç•™å…³é”®é¡ºåº)
    preserve_order = ['SNI', 'ExtendedMasterSecret', 'SupportedCurves']
    randomize_extensions(varied['extensions'], preserve_order)
    
    return varied

# è¿”å›990ä¸ªæ ·æœ¬çš„JSONåˆ—è¡¨
```

---

### Step 2: ç‰¹å¾æå–å¼•æ“

**æ–‡ä»¶**: `scripts/extract_features.py`

```python
def extract_features_from_sample(sample):
    """ä»å•ä¸ªæ ·æœ¬æå–52ç»´ç‰¹å¾"""
    
    features = {}
    
    # TLSç‰¹å¾
    features['tls_version'] = extract_tls_version(sample)
    features['num_cipher_suites'] = len(sample['cipher_suites'])
    features['num_extensions'] = len(sample['extensions'])
    # ... æ›´å¤šç‰¹å¾
    
    # Hashç‰¹å¾ (é›†åˆä½œä¸ºç‰¹å¾)
    features['cipher_suite_hash'] = hash_feature(sample['cipher_suites'])
    features['extension_set_hash'] = hash_feature(extract_ext_types(sample))
    features['curve_set_hash'] = hash_feature(extract_curves(sample))
    # ... æ›´å¤šhashç‰¹å¾
    
    # ç‰ˆæœ¬ç‰¹å¾
    browser_family, version = parse_config_name(sample['source_config'])
    features['browser_family'] = FAMILY_MAP[browser_family]
    features['browser_major_version'] = version.split('.')[0]
    features['browser_minor_version'] = version.split('.')[1] if '.' in version else 0
    
    return features

def hash_feature(items):
    """å°†é›†åˆè½¬æ¢ä¸ºæ•°å€¼ç‰¹å¾"""
    return hash(frozenset(items)) % (2**31)
```

---

### Step 3: æ ‡ç­¾ç”Ÿæˆä¸éªŒè¯

**æ–‡ä»¶**: `scripts/label_dataset.py`

```python
def create_labels(samples, config_mapping):
    """ä¸º990ä¸ªæ ·æœ¬åˆ›å»ºæ ‡ç­¾"""
    
    labels = []
    
    for idx, sample in enumerate(samples):
        config_name = sample['source_config']
        
        # ä»é…ç½®åè§£ææ ‡ç­¾
        # E.g.: "chrome_103" â†’ family=chrome, version=103
        parts = config_name.rsplit('_', 1)
        family = parts[0]
        version = parts[1] if len(parts) > 1 else "0"
        
        label = {
            'sample_id': f"sample_{idx:04d}",
            'source_config': config_name,
            'label_family': FAMILY_MAP[family],
            'label_version': int(version.split('.')[0]),
            'label_patch': int(version.split('.')[1]) if '.' in version else 0,
            'label_variant': detect_variant(config_name),  # PSK, PQç­‰
            'grease_variant': sample['grease_variant'],
            'session_id': sample['session_id'],
        }
        
        labels.append(label)
    
    return labels

def validate_dataset(features_df, labels_df):
    """éªŒè¯æ•°æ®è´¨é‡"""
    
    assert len(features_df) == len(labels_df) == 990
    assert features_df.isnull().sum().sum() == 0  # æ— ç¼ºå¤±å€¼
    
    # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒ
    family_counts = labels_df['label_family'].value_counts()
    print(f"Family distribution:\n{family_counts}")
    
    # ç»Ÿè®¡æ±‡æ€»
    stats = {
        'total_samples': 990,
        'feature_columns': 52,
        'unique_families': labels_df['label_family'].nunique(),
        'unique_versions': labels_df['label_version'].nunique(),
    }
    
    return stats
```

---

### Step 4: æ•°æ®é›†æ‰“åŒ…

**æ–‡ä»¶**: `scripts/package_dataset.py`

```python
def create_final_dataset():
    """æ•´åˆæ‰€æœ‰éƒ¨åˆ†ç”Ÿæˆæœ€ç»ˆæ•°æ®é›†"""
    
    # 1. åŠ è½½ç‰¹å¾å’Œæ ‡ç­¾
    features_df = pd.read_csv('dataset/features.csv')
    labels_df = pd.read_csv('dataset/labels.csv')
    
    # 2. åˆå¹¶
    dataset = pd.concat([features_df, labels_df], axis=1)
    
    # 3. æ•°æ®åˆ†å‰²: 80-10-10
    # ä¿è¯æ¯ä¸ªæµè§ˆå™¨æ—ç¾¤åœ¨ä¸‰ä¸ªé›†åˆä¸­éƒ½æœ‰ä»£è¡¨
    
    train, val, test = stratified_split(dataset, train=0.8, val=0.1, test=0.1)
    
    # 4. ä¿å­˜
    train.to_csv('dataset/train_set.csv', index=False)
    val.to_csv('dataset/val_set.csv', index=False)
    test.to_csv('dataset/test_set.csv', index=False)
    dataset.to_csv('dataset/20260213_ml_training_dataset.csv', index=False)
    
    # 5. å…ƒæ•°æ®
    metadata = {
        'version': '1.0.0',
        'created_date': '2026-02-13',
        'total_samples': 990,
        'features': 52,
        'families': 11,
        'train_samples': len(train),
        'val_samples': len(val),
        'test_samples': len(test),
    }
    
    with open('dataset/metadata.json', 'w') as f:
        json.dump(metadata, f, indent=2)
```

---

## è´¨é‡æ£€æŸ¥æ¸…å•

- [ ] æ ·æœ¬æ€»æ•°: 990 (66 Ã— 15)
- [ ] æ¯ä¸ªæµè§ˆå™¨é…ç½®æœ‰15ä¸ªæ ·æœ¬
- [ ] ç‰¹å¾å®Œæ•´: 52ç»´
- [ ] æ ‡ç­¾å‡†ç¡®: 100% (3çº§æ ‡ç­¾)
- [ ] æ— ç¼ºå¤±å€¼
- [ ] æ ‡ç­¾åˆ†å¸ƒå‡åŒ€ (æ¯ä¸ªæ—ç¾¤150æ ·æœ¬)
- [ ] ç‰¹å¾ç»Ÿè®¡åˆç† (æ— å¼‚å¸¸å€¼)
- [ ] è®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ†å‰²: 80%/10%/10%
- [ ] å…ƒæ•°æ®å®Œæ•´
- [ ] å¯é‡ç° (è®°å½•æ‰€æœ‰éšæœºç§å­)

---

## äº¤ä»˜ç‰©æ¸…å•

**ä»£ç **:
- [ ] scripts/generate_ml_dataset.py (990ä¸ªæ ·æœ¬ç”Ÿæˆ)
- [ ] scripts/extract_features.py (52ç»´ç‰¹å¾æå–)
- [ ] scripts/label_dataset.py (æ ‡ç­¾åŒ–å’ŒéªŒè¯)
- [ ] scripts/package_dataset.py (æ•°æ®é›†æ•´åˆ)

**æ•°æ®**:
- [ ] dataset/20260213_ml_training_dataset.csv (990è¡Œ Ã— 60åˆ—)
- [ ] dataset/train_set.csv (792è¡Œ)
- [ ] dataset/val_set.csv (99è¡Œ)
- [ ] dataset/test_set.csv (99è¡Œ)
- [ ] dataset/metadata.json (æ•°æ®é›†å…ƒæ•°æ®)
- [ ] dataset/feature_schema.json (ç‰¹å¾å®šä¹‰)

**æ–‡æ¡£**:
- [ ] dataset/README.md (æ•°æ®é›†ä½¿ç”¨è¯´æ˜)
- [ ] PHASE_7_2_EXECUTION_REPORT.md (æ‰§è¡Œæ€»ç»“)

---

## æ—¶é—´è¡¨

| é˜¶æ®µ | å·¥ä½œå†…å®¹ | é¢„è®¡æ—¶é—´ | çŠ¶æ€ |
|------|---------|---------|------|
| Stage 1 | æ ·æœ¬ç”Ÿæˆä¸æ‰©å…… | 2å°æ—¶ | â³ å‡†å¤‡ |
| Stage 2 | ç‰¹å¾æå– | 3å°æ—¶ | â³ å‡†å¤‡ |
| Stage 3 | æ ‡ç­¾åŒ–ä¸éªŒè¯ | 2å°æ—¶ | â³ å‡†å¤‡ |
| Stage 4 | æ•°æ®é›†æ‰“åŒ… | 1å°æ—¶ | â³ å‡†å¤‡ |
| **æ€»è®¡** | **æ•°æ®é›†æ„å»º** | **8å°æ—¶** | â³ è®¡åˆ’ä¸­ |

---

## ä¸‹ä¸€é˜¶æ®µå…¥å£

**Phase 7.3: MLåˆ†ç±»å™¨å¼€å‘** (16å°æ—¶)

**è¾“å…¥**:
- 990ä¸ªæ ·æœ¬çš„å®Œæ•´æ•°æ®é›†
- 52ç»´ç‰¹å¾
- 3çº§æ ‡ç­¾ (family, version, variant)

**ç›®æ ‡**:
- å®ç°æµè§ˆå™¨æ—ç¾¤åˆ†ç±»å™¨ (>99% å‡†ç¡®ç‡)
- å®ç°ç‰ˆæœ¬åˆ†ç±»å™¨ (>95% å‡†ç¡®ç‡)
- å®ç°å˜ä½“åˆ†ç±»å™¨ (>90% å‡†ç¡®ç‡)

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2026-02-12 17:45:00 UTC  
**Phase**: 7.2 Planning
**çŠ¶æ€**: ğŸ“‹ Ready to Execute
