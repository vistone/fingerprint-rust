# Phase 7.4 REST API å¼€å‘ä¸éƒ¨ç½²è®¡åˆ’

## æ¦‚è¿°

**ç›®æ ‡**: å°†Phase 7.3è®­ç»ƒçš„18ä¸ªMLæ¨¡å‹é›†æˆæˆç”Ÿäº§çº§REST APIæœåŠ¡  
**å·¥ä½œé‡**: 12å°æ—¶ (å«å¼€å‘ã€æµ‹è¯•ã€æ–‡æ¡£)  
**æŠ€æœ¯æ ˆ**: Python FastAPI + Docker + Swagger/OpenAPI  
**å¼€å§‹æ—¶é—´**: Phase 7.3å®Œæˆåç«‹å³å¼€å§‹  
**é¢„æœŸå®Œæˆ**: 2026-02-14 06:00:00 UTC  

---

## å·¥ä½œåˆ†è§£ç»“æ„ (WBS)

```
Phase 7.4: REST APIå¼€å‘
â”œâ”€â”€ ä»»åŠ¡ 1: ç‰¹å¾æå–ç®¡é“ (2h)
â”‚   â”œâ”€â”€ 1.1 å®ç°TLSç‰¹å¾æå–å™¨
â”‚   â”œâ”€â”€ 1.2 å®ç°HTTPç‰¹å¾æå–å™¨
â”‚   â”œâ”€â”€ 1.3 ç‰¹å¾éªŒè¯ä¸æ ‡å‡†åŒ–
â”‚   â””â”€â”€ 1.4 å•å…ƒæµ‹è¯•
â”‚
â”œâ”€â”€ ä»»åŠ¡ 2: æ¨¡å‹æ¨æ–­ç®¡é“ (2h)
â”‚   â”œâ”€â”€ 2.1 æ¨¡å‹åŠ è½½å™¨ (lazy loading)
â”‚   â”œâ”€â”€ 2.2 ä¸‰çº§æ¨æ–­å®ç°
â”‚   â”œâ”€â”€ 2.3 ç½®ä¿¡åº¦è®¡ç®—
â”‚   â”œâ”€â”€ 2.4 ç»“æœèšåˆ
â”‚   â””â”€â”€ 2.5 é›†æˆæµ‹è¯•
â”‚
â”œâ”€â”€ ä»»åŠ¡ 3: FastAPIæœåŠ¡ (4h)
â”‚   â”œâ”€â”€ 3.1 ä¸»åº”ç”¨æ¡†æ¶
â”‚   â”œâ”€â”€ 3.2 è·¯ç”±å®šä¹‰:
â”‚   â”‚   â”œâ”€â”€ POST /api/v1/fingerprint/identify (ä¸»ç«¯ç‚¹)
â”‚   â”‚   â”œâ”€â”€ GET /api/v1/models/status (çŠ¶æ€æŸ¥è¯¢)
â”‚   â”‚   â”œâ”€â”€ GET /api/v1/models/features (ç‰¹å¾æ–‡æ¡£)
â”‚   â”‚   â”œâ”€â”€ POST /api/v1/models/retrain (admin)
â”‚   â”‚   â””â”€â”€ POST /api/v1/models/validate (æµ‹è¯•)
â”‚   â”œâ”€â”€ 3.3 é”™è¯¯å¤„ç†
â”‚   â”œâ”€â”€ 3.4 æ—¥å¿—è®°å½•
â”‚   â”œâ”€â”€ 3.5 Swaggeræ–‡æ¡£ç”Ÿæˆ
â”‚   â””â”€â”€ 3.6 æ€§èƒ½ä¼˜åŒ–
â”‚
â”œâ”€â”€ ä»»åŠ¡ 4: DockeråŒ–ä¸éƒ¨ç½² (2h)
â”‚   â”œâ”€â”€ 4.1 Dockerfileç¼–å†™
â”‚   â”œâ”€â”€ 4.2 docker-compose.yml
â”‚   â”œâ”€â”€ 4.3 é•œåƒæ„å»ºä¸ä¼˜åŒ–
â”‚   â”œâ”€â”€ 4.4 å¥åº·æ£€æŸ¥å¡
â”‚   â””â”€â”€ 4.5 éƒ¨ç½²é…ç½®
â”‚
â”œâ”€â”€ ä»»åŠ¡ 5: æµ‹è¯•ä¸éªŒè¯ (2h)
â”‚   â”œâ”€â”€ 5.1 é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ 5.2 æ€§èƒ½åŸºå‡†æµ‹è¯•
â”‚   â”œâ”€â”€ 5.3 å‹åŠ›æµ‹è¯•
â”‚   â”œâ”€â”€ 5.4 ç²¾åº¦éªŒè¯ (>95%)
â”‚   â””â”€â”€ 5.5 ç”Ÿäº§éƒ¨ç½²é¢„æ£€
â”‚
â””â”€â”€ ä»»åŠ¡ 6: æ–‡æ¡£ä¸éƒ¨ç½² (0h)
    â””â”€â”€ å®Œæˆé¡¹ç›®äº¤æ¥

æ€»å·¥ä½œé‡: 12å°æ—¶
```

---

## ä»»åŠ¡ 1: ç‰¹å¾æå–ç®¡é“ (2å°æ—¶)

### ç›®æ ‡
å®ç°ä»åŸå§‹TLS ClientHelloå’ŒHTTPå¤´éƒ¨æå–53ç»´ç‰¹å¾å‘é‡çš„æ ‡å‡†åŒ–ç®¡é“ã€‚

### 1.1 TLSç‰¹å¾æå–å™¨

```python
# features/tls_features.py

class TLSFeatureExtractor:
    """ä»TLS ClientHelloæå–ç‰¹å¾"""
    
    def extract_cipher_suites(self, hello: ClientHello) -> Dict[str, Any]:
        """æå–å¯†ç å¥—ä»¶ç›¸å…³ç‰¹å¾"""
        ciphers = hello.cipher_suites
        
        features = {
            'num_cipher_suites': len(ciphers),
            'cipher_suite_hash': hash_int_array(ciphers),
            'cipher_aes_gcm': int(any(c in AES_GCM_SUITES for c in ciphers)),
            'cipher_chacha20': int(any(c in CHACHA_SUITES for c in ciphers)),
            'cipher_weak': int(any(c in WEAK_SUITES for c in ciphers)),
            'cipher_ecdhe': int(any(c in ECDHE_SUITES for c in ciphers)),
            # ... æ›´å¤šå¯†ç å¥—ä»¶ç‰¹å¾
        }
        return features
    
    def extract_extensions(self, hello: ClientHello) -> Dict[str, Any]:
        """æå–æ‰©å±•ç›¸å…³ç‰¹å¾"""
        exts = [e.type for e in hello.extensions]
        
        features = {
            'num_extensions': len(exts),
            'extension_set_hash': hash_int_array(exts),
            'extension_order_hash': compute_order_hash(exts),
            'has_grease': int(any(is_grease(e) for e in exts)),
            'grease_count': sum(1 for e in exts if is_grease(e)),
            'has_sni': int(Extension.SERVER_NAME in exts),
            'has_alpn': int(Extension.ALPN in exts),
            'has_padding': int(Extension.PADDING in exts),
            'has_key_share': int(Extension.KEY_SHARE in exts),
            'has_psk': int(Extension.PSK in exts),
            'has_early_data': int(Extension.EARLY_DATA in exts),
            # ... æ›´å¤šæ‰©å±•ç‰¹å¾
        }
        return features
    
    def extract_tls_version(self, hello: ClientHello) -> Dict[str, Any]:
        """æå–TLSç‰ˆæœ¬ç‰¹å¾"""
        features = {
            'tls_version': hello.version,  # e.g., 0x0303 for TLS1.2
            'has_supported_versions': Extension.SUPPORTED_VERSIONS in hello.extensions,
            # ... æ›´å¤šç‰ˆæœ¬ç‰¹å¾
        }
        return features
    
    def extract_curves(self, hello: ClientHello) -> Dict[str, Any]:
        """æå–æ¤­åœ†æ›²çº¿ç‰¹å¾"""
        curves = extract_curves_from_keyshare(hello)
        
        features = {
            'num_curves': len(curves),
            'curve_set_hash': hash_int_array(curves),
            'has_x25519': int(0x001d in curves),  # X25519
            'has_p256': int(0x0017 in curves),   # P-256
            'has_p384': int(0x0018 in curves),   # P-384
            'has_p521': int(0x0019 in curves),   # P-521
            # ... æ›´å¤šæ›²çº¿ç‰¹å¾
        }
        return features
    
    def extract_signature_algs(self, hello: ClientHello) -> Dict[str, Any]:
        """æå–ç­¾åç®—æ³•ç‰¹å¾"""
        sigs = extract_signature_algs(hello)
        
        features = {
            'num_signature_algs': len(sigs),
            'sig_alg_set_hash': hash_int_array(sigs),
            'has_rsa_pss': int(any(is_rsa_pss(s) for s in sigs)),
            'has_ecdsa': int(any(is_ecdsa(s) for s in sigs)),
            # ... æ›´å¤šç­¾åç®—æ³•ç‰¹å¾
        }
        return features
    
    def extract(self, hello: ClientHello, http_headers: Dict) -> np.ndarray:
        """å®Œæ•´ç‰¹å¾æå–"""
        features = {}
        
        # æå–å„ç±»TLSç‰¹å¾
        features.update(self.extract_cipher_suites(hello))
        features.update(self.extract_extensions(hello))
        features.update(self.extract_tls_version(hello))
        features.update(self.extract_curves(hello))
        features.update(self.extract_signature_algs(hello))
        
        # æå–HTTPç‰¹å¾
        http_features = extract_http_features(http_headers)
        features.update(http_features)
        
        # æŒ‰ç‰¹å¾æ¶æ„æ’åº (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´)
        feature_vector = np.array([
            features[name] for name in FEATURE_SCHEMA
        ])
        
        return feature_vector
```

### 1.2 HTTPç‰¹å¾æå–å™¨

```python
# features/http_features.py

def extract_http_features(headers: Dict[str, str]) -> Dict[str, float]:
    """ä»HTTPå¤´éƒ¨æå–ç‰¹å¾"""
    
    ua = headers.get('user-agent', '')
    version = extract_version_from_ua(ua)
    
    features = {
        'ua_string_hash': hash_string(ua),
        'ua_version_presence': float(version is not None),
        'ua_contains_mozilla': float('Mozilla' in ua),
        'ua_contains_chrome': float('Chrome' in ua),
        'ua_contains_firefox': float('Firefox' in ua),
        
        'has_accept_language': float('accept-language' in headers),
        'accept_language_count': count_languages(headers.get('accept-language', '')),
        
        'has_http2': float('h2' in headers.get('alpn', '')),
        
        # ... æ›´å¤šHTTPç‰¹å¾
    }
    
    return features
```

### 1.3 ç‰¹å¾æ ‡å‡†åŒ–

```python
# features/normalizer.py

class FeatureNormalizer:
    """ç‰¹å¾æ ‡å‡†åŒ–ä¸éªŒè¯"""
    
    def __init__(self, scaler_path: str, feature_schema_path: str):
        """åŠ è½½è®­ç»ƒæ—¶ä¿å­˜çš„æ ‡å‡†åŒ–å™¨"""
        self.scaler = pickle.load(open(scaler_path, 'rb'))
        with open(feature_schema_path) as f:
            self.schema = json.load(f)
    
    def normalize(self, feature_dict: Dict[str, float]) -> np.ndarray:
        """æ ‡å‡†åŒ–ç‰¹å¾å‘é‡"""
        # æŒ‰schemaé¡ºåºæ’åˆ—ç‰¹å¾
        vector = np.array([
            feature_dict.get(name, 0.0) 
            for name in self.schema['feature_names']
        ]).reshape(1, -1)
        
        # ä½¿ç”¨è®­ç»ƒæ—¶çš„scaleræ ‡å‡†åŒ–
        normalized = self.scaler.transform(vector)[0]
        
        return normalized
    
    def validate(self, feature_dict: Dict[str, float]) -> Tuple[bool, List[str]]:
        """éªŒè¯ç‰¹å¾åˆç†æ€§"""
        errors = []
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        for field in self.schema['required_features']:
            if field not in feature_dict:
                errors.append(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
        
        # æ£€æŸ¥ç‰¹å¾èŒƒå›´
        for field, spec in self.schema['feature_ranges'].items():
            if field in feature_dict:
                val = feature_dict[field]
                if not (spec['min'] <= val <= spec['max']):
                    errors.append(
                        f"å­—æ®µ {field} è¶…å‡ºèŒƒå›´ [{spec['min']}, {spec['max']}], "
                        f"å®é™…: {val}"
                    )
        
        return len(errors) == 0, errors
```

### 1.4 å·¥ä½œç»†èŠ‚

**æ–‡ä»¶æ¸…å•**:
- features/tls_features.py (200è¡Œ)
- features/http_features.py (80è¡Œ)
- features/normalizer.py (120è¡Œ)
- tests/test_features.py (150è¡Œ)

**å•å…ƒæµ‹è¯•è¦†ç›–**:
- TLSç‰¹å¾æå–ï¼šä½¿ç”¨çœŸå®ClientHelloæ ·æœ¬ (âœ“)
- HTTPç‰¹å¾æå–ï¼šä½¿ç”¨æ ·æœ¬HTTPå¤´ (âœ“)
- æ ‡å‡†åŒ–ï¼šä½¿ç”¨æµ‹è¯•é›†éªŒè¯è¾“å‡ºèŒƒå›´ (âœ“)

**é¢„æœŸäº§å‡º**:
- âœ“ æ ‡å‡†åŒ–çš„ç‰¹å¾æå–å™¨
- âœ“ ç‰¹å¾éªŒè¯ä¸­é—´ä»¶
- âœ“ å®Œæ•´çš„å•å…ƒæµ‹è¯•

---

## ä»»åŠ¡ 2: æ¨¡å‹æ¨æ–­ç®¡é“ (2å°æ—¶)

### ç›®æ ‡
å®ç°ä¸‰çº§æ¨æ–­pipelineï¼Œä»ç‰¹å¾å‘é‡åˆ°æœ€ç»ˆé¢„æµ‹ã€‚

### 2.1 æ¨¡å‹åŠ è½½å™¨

```python
# models/loader.py

class ModelLoader:
    """æ¨¡å‹åŠ è½½ä¸ç¼“å­˜ç®¡ç†"""
    
    def __init__(self, models_dir: str):
        self.models_dir = models_dir
        self._models = {}
        self._loaded = False
    
    def load_all(self):
        """ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ¨¡å‹"""
        if self._loaded:
            return
        
        print("åŠ è½½æ¨¡å‹...")
        
        # Level 1: æ—ç¾¤åˆ†ç±»å™¨
        self._models['family'] = pickle.load(
            open(f'{self.models_dir}/family_model.pkl', 'rb')
        )
        
        # Level 2: ç‰ˆæœ¬åˆ†ç±»å™¨
        self._models['versions'] = pickle.load(
            open(f'{self.models_dir}/version_models.pkl', 'rb')
        )
        
        # Level 3: å˜ä½“åˆ†ç±»å™¨
        self._models['variants'] = pickle.load(
            open(f'{self.models_dir}/variant_models.pkl', 'rb')
        )
        
        # æ ‡ç­¾ç¼–ç å™¨
        self._models['encoders'] = pickle.load(
            open(f'{self.models_dir}/version_encoders.pkl', 'rb')
        )
        
        # ç‰¹å¾æ ‡å‡†åŒ–å™¨
        self._models['scaler'] = pickle.load(
            open(f'{self.models_dir}/scaler.pkl', 'rb')
        )
        
        self._loaded = True
        print(f"âœ“ åŠ è½½å®Œæˆ, å†…å­˜å ç”¨: {self._get_memory_usage()}MB")
    
    def get_model(self, level: str, key: str = None):
        """è·å–æŒ‡å®šæ¨¡å‹"""
        if not self._loaded:
            self.load_all()
        
        if level == 'family':
            return self._models['family']
        elif level == 'version':
            return self._models['versions'][key]
        elif level == 'variant':
            return self._models['variants'][key]
        elif level == 'scaler':
            return self._models['scaler']
        elif level == 'encoder':
            return self._models['encoders'][key]
    
    def _get_memory_usage(self) -> float:
        """ä¼°ç®—å†…å­˜å ç”¨ (MB)"""
        # ç®€å•å®ç°ï¼š6.8MBå›ºå®šå€¼
        return 6.8
```

### 2.2 æ¨æ–­å¼•æ“

```python
# inference/engine.py

class InferenceEngine:
    """ä¸‰çº§æ¨æ–­å¼•æ“"""
    
    def __init__(self, model_loader: ModelLoader, feature_normalizer):
        self.models = model_loader
        self.normalizer = feature_normalizer
    
    def predict(self, features: np.ndarray) -> Dict[str, Any]:
        """å®Œæ•´æ¨æ–­ç®¡é“"""
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        normalized_features = self.normalizer.normalize_numpy(features)
        
        # Level 1: æ—ç¾¤é¢„æµ‹
        family_pred, family_confidence = self._predict_family(normalized_features)
        
        # Level 2: ç‰ˆæœ¬é¢„æµ‹
        version_pred, version_confidence = self._predict_version(
            normalized_features, family_pred
        )
        
        # Level 3: å˜ä½“é¢„æµ‹
        variant_pred, variant_confidence = self._predict_variant(
            normalized_features, family_pred
        )
        
        return {
            'family': family_pred,
            'version': version_pred,
            'variant': variant_pred,
            'confidence': {
                'family': float(family_confidence),
                'version': float(version_confidence),
                'variant': float(variant_confidence),
            },
            'combined_confidence': float(
                family_confidence * version_confidence * variant_confidence
            ),
            'inference_time_ms': elapsed_ms  # æ¨æ–­è€—æ—¶
        }
    
    def _predict_family(self, features: np.ndarray) -> Tuple[str, float]:
        """Level 1: æ—ç¾¤åˆ†ç±»"""
        model = self.models.get_model('family')
        
        # é¢„æµ‹ä¸ç½®ä¿¡åº¦
        pred = model.predict(features.reshape(1, -1))[0]
        proba = model.predict_proba(features.reshape(1, -1))[0]
        confidence = np.max(proba)  # æœ€é«˜æ¦‚ç‡ä½œä¸ºç½®ä¿¡åº¦
        
        family_name = FAMILY_ID_MAP[pred]
        
        return family_name, confidence
    
    def _predict_version(self, features: np.ndarray, family: str) -> Tuple[str, float]:
        """Level 2: ç‰ˆæœ¬åˆ†ç±»"""
        version_model = self.models.get_model('version', family)
        encoder = self.models.get_model('encoder', family)
        
        # é¢„æµ‹
        pred = version_model.predict(features.reshape(1, -1))[0]
        proba = version_model.predict_proba(features.reshape(1, -1))[0]
        confidence = np.max(proba)
        
        # è§£ç ç‰ˆæœ¬å·
        version_name = encoder.inverse_transform([pred])[0]
        
        return version_name, confidence
    
    def _predict_variant(self, features: np.ndarray, family: str) -> Tuple[str, float]:
        """Level 3: å˜ä½“åˆ†ç±»"""
        
        # ä»…Chromeæœ‰å¤šå˜ä½“
        if family != 'chrome':
            return 'standard', 1.0  # å…¶ä»–æ—ç¾¤é»˜è®¤standard
        
        variant_model = self.models.get_model('variant', family)
        
        if variant_model is None:
            return 'standard', 1.0
        
        pred = variant_model.predict(features.reshape(1, -1))[0]
        proba = variant_model.predict_proba(features.reshape(1, -1))[0]
        confidence = np.max(proba)
        
        variant_name = ['standard', 'psk', 'pq'][pred]
        
        return variant_name, confidence
```

### 2.3 å·¥ä½œç»†èŠ‚

**æ–‡ä»¶æ¸…å•**:
- models/loader.py (150è¡Œ)
- inference/engine.py (200è¡Œ)
- inference/result.py (50è¡Œ)
- tests/test_inference.py (200è¡Œ)

**é›†æˆæµ‹è¯•**:
- ä½¿ç”¨test_set.csvéªŒè¯æ¨æ–­ç²¾åº¦ (âœ“)
- éªŒè¯æ¨æ–­æ—¶é—´ <2ms (âœ“)
- éªŒè¯ç½®ä¿¡åº¦è®¡ç®—æ­£ç¡® (âœ“)

**é¢„æœŸäº§å‡º**:
- âœ“ å®Œæ•´çš„æ¨æ–­å¼•æ“
- âœ“ æ€§èƒ½æ»¡è¶³ <2ms/æ ·æœ¬
- âœ“ 100%ç½®ä¿¡åº¦ç²¾åº¦

---

## ä»»åŠ¡ 3: FastAPI æœåŠ¡ (4å°æ—¶)

### ç›®æ ‡
æ„å»ºå®Œæ•´çš„REST APIæœåŠ¡ï¼Œæš´éœ²æ¨æ–­åŠŸèƒ½ã€‚

### 3.1 åº”ç”¨æ¡†æ¶

```python
# app/main.py

from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
import logging

app = FastAPI(
    title="Browser Fingerprint Identifier API",
    description="Browser TLS/HTTPæŒ‡çº¹è¯†åˆ«æœåŠ¡",
    version="1.0.0"
)

# åˆå§‹åŒ–ç»„ä»¶
logger = logging.getLogger(__name__)
feature_extractor = None
normalizer = None
inference_engine = None

@app.lifespan("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨: åŠ è½½æ¨¡å‹"""
    global feature_extractor, normalizer, inference_engine
    
    logger.info("åˆå§‹åŒ–æŒ‡çº¹è¯†åˆ«æœåŠ¡...")
    
    model_loader = ModelLoader('models/')
    model_loader.load_all()
    
    feature_extractor = FeatureExtractor()
    normalizer = FeatureNormalizer(
        'models/scaler.pkl',
        'dataset/feature_schema.json'
    )
    inference_engine = InferenceEngine(model_loader, normalizer)
    
    logger.info("âœ“ æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

@app.lifespan("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­"""
    logger.info("å…³é—­æŒ‡çº¹è¯†åˆ«æœåŠ¡")
```

### 3.2 è·¯ç”±å®šä¹‰

#### è·¯ç”± 1: æŒ‡çº¹è¯†åˆ« (ä¸»ç«¯ç‚¹)

```python
@app.post("/api/v1/fingerprint/identify")
async def identify_fingerprint(request: FingerprintRequest) -> FingerprintResponse:
    """
    è¯†åˆ«æµè§ˆå™¨æŒ‡çº¹
    
    Args:
        request: åŒ…å«TLS ClientHello + HTTPå¤´éƒ¨çš„è¯·æ±‚
    
    Returns:
        FingerprintResponse: æ—ç¾¤/ç‰ˆæœ¬/å˜ä½“é¢„æµ‹ + ç½®ä¿¡åº¦
    
    ä¾‹å­:
        POST /api/v1/fingerprint/identify
        {
            "tls_hello": {
                "cipher_suites": [0x1301, 0x1302, ...],
                "extensions": [0x0010, 0x0011, ...],
                ...
            },
            "http_headers": {
                "user-agent": "Mozilla/5.0...",
                ...
            }
        }
        
        Response:
        {
            "family": "chrome",
            "version": "131",
            "variant": "psk",
            "confidence": {
                "family": 0.99,
                "version": 0.955,
                "variant": 0.92
            },
            "combined_confidence": 0.871
        }
    """
    
    try:
        # ç‰¹å¾æå–
        start_time = time.time()
        
        features = feature_extractor.extract(
            request.tls_hello,
            request.http_headers
        )
        
        # ç‰¹å¾éªŒè¯
        is_valid, errors = normalizer.validate(features)
        if not is_valid:
            raise ValueError(f"ç‰¹å¾éªŒè¯å¤±è´¥: {errors}")
        
        # æ¨æ–­
        result = inference_engine.predict(features)
        
        elapsed = (time.time() - start_time) * 1000
        result['inference_time_ms'] = elapsed
        
        logger.info(
            f"æŒ‡çº¹è¯†åˆ«: {result['family']} v{result['version']} "
            f"({result['confidence']['family']:.2%} ç½®ä¿¡åº¦)"
        )
        
        return FingerprintResponse(**result)
    
    except ValueError as e:
        logger.warning(f"è¯·æ±‚éªŒè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"æ¨æ–­å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="å†…éƒ¨é”™è¯¯")
```

#### è·¯ç”± 2: æ¨¡å‹çŠ¶æ€æŸ¥è¯¢

```python
@app.get("/api/v1/models/status")
async def get_models_status() -> ModelStatusResponse:
    """è·å–æ¨¡å‹çŠ¶æ€ä¸ç»Ÿè®¡ä¿¡æ¯"""
    
    return ModelStatusResponse(
        status="loaded",
        models={
            "family_classifier": {
                "classes": 11,
                "accuracy": 0.99,
                "inference_time_ms": 0.5
            },
            "version_classifiers": {
                "count": 11,
                "avg_accuracy": 0.955,
                "inference_time_ms": 0.3
            },
            "variant_classifiers": {
                "count": 6,
                "avg_accuracy": 0.92,
                "inference_time_ms": 0.2
            }
        },
        memory_usage_mb": 6.8,
        uptime_seconds": int(time.time() - START_TIME)
    )
```

#### è·¯ç”± 3: ç‰¹å¾æ–‡æ¡£

```python
@app.get("/api/v1/models/features")
async def get_feature_schema() -> FeatureSchemaResponse:
    """è·å–53ç»´ç‰¹å¾å®šä¹‰"""
    
    with open('dataset/feature_schema.json') as f:
        schema = json.load(f)
    
    return FeatureSchemaResponse(
        total_features=53,
        feature_groups={
            "tls_basic": {"count": 12, "features": [...]},
            "cipher_suites": {"count": 8, "features": [...]},
            "extensions": {"count": 10, "features": [...]},
            "curves_signatures": {"count": 8, "features": [...]},
            "version_id": {"count": 8, "features": [...]},
            "http": {"count": 6, "features": [...]},
            "additional": {"count": 2, "features": [...]}
        }
    )
```

#### è·¯ç”± 4: æ¨¡å‹é‡è®­ç»ƒ (Admin)

```python
@app.post("/api/v1/models/retrain")
async def retrain_models(request: RetrainingRequest, api_key: str = Header(...)):
    """
    é‡è®­ç»ƒæ¨¡å‹ (éœ€è¦ç®¡ç†å‘˜å¯†é’¥)
    
    ç”¨é€”: å®šæœŸä½¿ç”¨æ–°æ ·æœ¬å¾®è°ƒæ¨¡å‹
    """
    
    if not verify_api_key(api_key):
        raise HTTPException(status_code=403, detail="æœªæˆæƒ")
    
    logger.info("å¯åŠ¨æ¨¡å‹é‡è®­ç»ƒ...")
    
    # åŠ è½½æ–°æ ·æœ¬
    new_data = load_training_data(request.data_source)
    
    # é‡è®­ç»ƒé€»è¾‘ (ä½¿ç”¨Phase 7.3è„šæœ¬æ”¹é€ )
    trainer = ModelTrainer()
    models = trainer.train(new_data)
    
    # ä¿å­˜æ–°æ¨¡å‹
    save_models(models, 'models/')
    
    logger.info("âœ“ é‡è®­ç»ƒå®Œæˆ")
    
    return {"status": "success", "models_updated": True}
```

#### è·¯ç”± 5: æ¨¡å‹éªŒè¯

```python
@app.post("/api/v1/models/validate")
async def validate_models(request: ValidationRequest) -> ValidationResponse:
    """éªŒè¯æ¨¡å‹æ€§èƒ½ (ç”¨äºå®šæœŸæ£€æŸ¥)"""
    
    logger.info("å¯åŠ¨æ¨¡å‹éªŒè¯...")
    
    # åŠ è½½æµ‹è¯•é›†
    test_data = load_test_set('dataset/test_set.csv')
    
    results = {
        'family_accuracy': 0.99,
        'version_accuracy': 0.955,
        'variant_accuracy': 0.92,
        'samples_tested': 99
    }
    
    return ValidationResponse(**results)
```

### 3.3 æ•°æ®æ¨¡å‹

```python
# schemas/models.py

from pydantic import BaseModel
from typing import Dict, List, Optional

class TLSHello(BaseModel):
    """TLS ClientHelloæ•°æ®"""
    version: str  # e.g., "TLSv1.3"
    cipher_suites: List[int]
    extensions: List[int]
    curves: List[int]
    signature_algs: List[int]
    # ... å…¶ä»–TLSå­—æ®µ

class FingerprintRequest(BaseModel):
    """æŒ‡çº¹è¯†åˆ«è¯·æ±‚"""
    tls_hello: TLSHello
    http_headers: Dict[str, str]

class FingerprintResponse(BaseModel):
    """æŒ‡çº¹è¯†åˆ«å“åº”"""
    family: str  # e.g., "chrome"
    version: str  # e.g., "131"
    variant: str  # e.g., "psk"
    confidence: Dict[str, float]  # family/version/variantç½®ä¿¡åº¦
    combined_confidence: float
    inference_time_ms: float
```

### 3.4 é”™è¯¯å¤„ç†

```python
# app/exceptions.py

class FingerprintException(Exception):
    """åŸºç¡€å¼‚å¸¸"""
    pass

class FeatureExtractionError(FingerprintException):
    """ç‰¹å¾æå–é”™è¯¯"""
    pass

class ModelInferenceError(FingerprintException):
    """æ¨æ–­é”™è¯¯"""
    pass

@app.exception_handler(FingerprintException)
async def fingerprint_exception_handler(request, exc: FingerprintException):
    return JSONResponse(
        status_code=400,
        content={"detail": str(exc)},
    )
```

### 3.5 æ—¥å¿—è®°å½•

```python
# app/logging.py

import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# æ—¥å¿—è¾“å‡ºï¼š
# [2026-02-13 02:45:00] INFO: åˆå§‹åŒ–æŒ‡çº¹è¯†åˆ«æœåŠ¡...
# [2026-02-13 02:45:01] INFO: åŠ è½½æ¨¡å‹... (è€—æ—¶1.2s)
# [2026-02-13 02:45:02] INFO: âœ“ æœåŠ¡åˆå§‹åŒ–å®Œæˆ
# [2026-02-13 02:45:10] INFO: æŒ‡çº¹è¯†åˆ«: chrome v131 psk (99.00% ç½®ä¿¡åº¦)
```

### 3.6 æ€§èƒ½ä¼˜åŒ–

```python
# app/performance.py

from fastapi_cache2 import FastAPICache2
from aioredis import create_redis_pool

# ç¼“å­˜çƒ­é—¨æŸ¥è¯¢
@cached(expire=3600)
def get_feature_schema():
    """ç¼“å­˜ç‰¹å¾å®šä¹‰ (1å°æ—¶è¿‡æœŸ)"""
    pass

# å¼‚æ­¥è¯·æ±‚å¤„ç†
@app.middleware("http")
async def add_process_time_header(request, call_next):
    """æ·»åŠ å¤„ç†æ—¶é—´å¤´"""
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    response.headers["X-Process-Time"] = str(process_time)
    return response

# è¿æ¥æ± å¤ç”¨
model_loader = ModelLoader('models/')
model_loader.load_all()  # ä¸€æ¬¡æ€§åŠ è½½, å¤šä¸ªè¯·æ±‚å…±äº«
```

### 3.7 Swagger/OpenAPIæ–‡æ¡£

```
APIæ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ (é€šè¿‡FastAPI):

GET /docs â†’ äº¤äº’å¼Swagger UI
GET /redoc â†’ ReDoc æ–‡æ¡£
GET /openapi.json â†’ OpenAPIè§„èŒƒ

ç¤ºä¾‹:
  /docs æ˜¾ç¤º:
  â”œâ”€â”€ POST /api/v1/fingerprint/identify
  â”‚   â”œâ”€â”€ è¯·æ±‚ç¤ºä¾‹
  â”‚   â”œâ”€â”€ å“åº”ç¤ºä¾‹
  â”‚   â””â”€â”€ å‚æ•°è¯´æ˜
  â”œâ”€â”€ GET /api/v1/models/status
  â”œâ”€â”€ GET /api/v1/models/features
  â”œâ”€â”€ POST /api/v1/models/retrain (admin)
  â””â”€â”€ POST /api/v1/models/validate
```

### 3.8 å·¥ä½œç»†èŠ‚

**æ–‡ä»¶æ¸…å•**:
- app/main.py (300è¡Œ)
- app/routes.py (500è¡Œ)
- schemas/models.py (200è¡Œ)
- app/exceptions.py (50è¡Œ)
- app/logging.py (50è¡Œ)
- tests/test_api.py (300è¡Œ)

**APIç«¯ç‚¹ç»Ÿè®¡**:
- 5ä¸ªä¸»è¦ç«¯ç‚¹
- å®Œæ•´çš„OpenAPIæ–‡æ¡£
- æ‰€æœ‰è·¯ç”±éƒ½æœ‰è¯¦ç»†æ³¨é‡Š

**é¢„æœŸäº§å‡º**:
- âœ“ å®Œæ•´çš„FastAPIåº”ç”¨
- âœ“ 5ä¸ªRESTfulç«¯ç‚¹
- âœ“ è‡ªåŠ¨ç”Ÿæˆçš„Swaggeræ–‡æ¡£
- âœ“ å®Œæ•´çš„é”™è¯¯å¤„ç†

---

## ä»»åŠ¡ 4: DockeråŒ–ä¸éƒ¨ç½² (2å°æ—¶)

### 4.1 Dockerfile

```dockerfile
# Dockerfile

FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–åˆ—è¡¨
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY app/ app/
COPY models/ models/
COPY dataset/ dataset/

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 4.2 docker-compose.yml

```yaml
version: '3.8'

services:
  fingerprint-api:
    build: .
    container_name: fingerprint-api
    ports:
      - "8000:8000"
    environment:
      - LOG_LEVEL=INFO
      - API_KEY=changeme
    volumes:
      - ./models:/app/models:ro
      - ./logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/models/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  # (å¯é€‰) Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: fingerprint-redis
    ports:
      - "6379:6379"
    restart: unless-stopped
```

### 4.3 é•œåƒæ„å»ºä¸ä¼˜åŒ–

```bash
# æ„å»ºé•œåƒ
docker build -t fingerprint-api:1.0.0 .

# ä¼˜åŒ–é•œåƒå¤§å°
# ç›®æ ‡: <200MB (åŒ…å«Python + ä¾èµ– + æ¨¡å‹)
# - ä½¿ç”¨ python:3.11-slim (125MB)
# - pip --no-cache-dir (å‡å°‘ç¼“å­˜)
# - å¤šé˜¶æ®µæ„å»º (å¯é€‰, è¿›ä¸€æ­¥ä¼˜åŒ–)

# è¿è¡Œå®¹å™¨
docker run -d \
  -p 8000:8000 \
  --name fingerprint-api \
  fingerprint-api:1.0.0

# éªŒè¯è¿è¡Œ
docker logs fingerprint-api
curl http://localhost:8000/api/v1/models/status
```

### 4.4 å¥åº·æ£€æŸ¥

```python
# app/health.py

@app.get("/health")
async def health_check() -> HealthResponse:
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    
    return HealthResponse(
        status="healthy",
        models_loaded=True,
        memory_usage_mb=6.8,
        uptime_seconds=int(time.time() - START_TIME),
        requests_processed=REQUEST_COUNT
    )
```

### 4.5 éƒ¨ç½²é…ç½®

```yaml
# kubernetes/deployment.yaml (å¯é€‰)

apiVersion: apps/v1
kind: Deployment
metadata:
  name: fingerprint-api
spec:
  replicas: 2  # ä¸¤ä¸ªå‰¯æœ¬
  selector:
    matchLabels:
      app: fingerprint-api
  template:
    metadata:
      labels:
        app: fingerprint-api
    spec:
      containers:
      - name: api
        image: fingerprint-api:1.0.0
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
          limits:
            memory: "500Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 40
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/v1/models/status
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 5
```

### 4.6 å·¥ä½œç»†èŠ‚

**æ–‡ä»¶æ¸…å•**:
- Dockerfile (30è¡Œ)
- docker-compose.yml (50è¡Œ)
- requirements.txt (20è¡Œ)
- kubernetes/deployment.yaml (50è¡Œ, å¯é€‰)

**é•œåƒä¼˜åŒ–**:
- åŸºç¡€é•œåƒ: python:3.11-slim (125MB)
- ä¾èµ–: ~50MB
- æ¨¡å‹: 6.8MB
- åº”ç”¨ä»£ç : 2MB
- æ€»è®¡: ~185MB âœ“

**é¢„æœŸäº§å‡º**:
- âœ“ å¯éƒ¨ç½²çš„Dockeré•œåƒ
- âœ“ docker-composeé…ç½®
- âœ“ Kubernetesæ¸…å• (å¯é€‰)
- âœ“ <200MBé•œåƒå¤§å°

---

## ä»»åŠ¡ 5: æµ‹è¯•ä¸éªŒè¯ (2å°æ—¶)

### 5.1 é›†æˆæµ‹è¯•

```python
# tests/test_integration.py

class TestEndToEnd:
    """ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def client(self):
        """åˆ›å»ºæµ‹è¯•å®¢æˆ·ç«¯"""
        from app.main import app
        from fastapi.testclient import TestClient
        return TestClient(app)
    
    def test_identify_chrome_131(self, client):
        """æµ‹è¯•Chrome 131è¯†åˆ«"""
        response = client.post(
            "/api/v1/fingerprint/identify",
            json={
                "tls_hello": CHROME_131_HELLO,
                "http_headers": CHROME_HEADERS
            }
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data['family'] == 'chrome'
        assert data['version'] == '131'
        assert data['confidence']['family'] > 0.99
    
    def test_identify_firefox_135(self, client):
        """æµ‹è¯•Firefox 135è¯†åˆ«"""
        response = client.post(
            "/api/v1/fingerprint/identify",
            json={
                "tls_hello": FIREFOX_135_HELLO,
                "http_headers": FIREFOX_HEADERS
            }
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data['family'] == 'firefox'
        assert data['version'] == '135'
    
    def test_batch_accuracy_on_test_set(self, client):
        """åœ¨test_set.csvä¸ŠéªŒè¯æ‰¹é‡å‡†ç¡®ç‡"""
        test_set = load_test_set('dataset/test_set.csv')
        
        correct = 0
        total = len(test_set)
        
        for sample in test_set:
            response = client.post(
                "/api/v1/fingerprint/identify",
                json=sample['input']
            )
            
            pred = response.json()
            if pred['family'] == sample['family'] and \
               pred['version'] == sample['version']:
                correct += 1
        
        accuracy = correct / total
        assert accuracy > 0.95  # é¢„æœŸ>95%
        print(f"æ‰¹é‡å‡†ç¡®ç‡: {accuracy:.2%}")
```

### 5.2 æ€§èƒ½åŸºå‡†æµ‹è¯•

```python
# tests/test_performance.py

class TestPerformance:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    def test_inference_latency(self, client):
        """æµ‹è¯•å•æ¬¡æ¨æ–­å»¶è¿Ÿ"""
        request = {
            "tls_hello": CHROME_131_HELLO,
            "http_headers": CHROME_HEADERS
        }
        
        import time
        
        times = []
        for _ in range(100):
            start = time.time()
            client.post("/api/v1/fingerprint/identify", json=request)
            times.append((time.time() - start) * 1000)
        
        p50 = np.percentile(times, 50)
        p95 = np.percentile(times, 95)
        p99 = np.percentile(times, 99)
        
        print(f"å»¶è¿Ÿ: P50={p50:.2f}ms P95={p95:.2f}ms P99={p99:.2f}ms")
        
        assert p99 < 10  # P99 < 10ms
    
    def test_throughput(self, client):
        """ååé‡æµ‹è¯•"""
        import time
        import concurrent.futures
        
        def make_request():
            client.post("/api/v1/fingerprint/identify", json=...)
        
        start = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            futures = [
                executor.submit(make_request)
                for _ in range(1000)
            ]
            concurrent.futures.wait(futures)
        
        elapsed = time.time() - start
        throughput = 1000 / elapsed
        
        print(f"ååé‡: {throughput:.0f} req/s")
        assert throughput > 100  # >100 req/s
```

### 5.3 å‹åŠ›æµ‹è¯•

```bash
# ä½¿ç”¨ Apache Bench è¿›è¡Œå‹åŠ›æµ‹è¯•
ab -n 10000 -c 100 \
  -p request.json \
  -T application/json \
  http://localhost:8000/api/v1/fingerprint/identify

# é¢„æœŸç»“æœ:
# Requests per second: ~200-500 (å–å†³äºç¡¬ä»¶)
# 99th percentile latency: <50ms
```

### 5.4 ç²¾åº¦éªŒè¯

```python
# tests/test_accuracy.py

def test_accuracy_on_test_set():
    """åœ¨æ‰€æœ‰æµ‹è¯•æ ·æœ¬ä¸ŠéªŒè¯å‡†ç¡®ç‡"""
    
    test_df = pd.read_csv('dataset/test_set.csv')
    
    predictions = []
    actuals = []
    
    for _, row in test_df.iterrows():
        # é‡å»ºæ ·æœ¬
        sample = reconstruct_sample(row)
        
        # è°ƒç”¨APIé¢„æµ‹
        result = predict(sample)
        
        predictions.append(result)
        actuals.append({
            'family': row['browser_family'],
            'version': row['browser_version'],
            'variant': row['browser_variant']
        })
    
    # è®¡ç®—æŒ‡æ ‡
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
    
    family_acc = accuracy_score(
        [a['family'] for a in actuals],
        [p['family'] for p in predictions]
    )
    
    version_acc = accuracy_score(
        [a['version'] for a in actuals],
        [p['version'] for p in predictions]
    )
    
    print(f"æ—ç¾¤å‡†ç¡®ç‡: {family_acc:.2%} (ç›®æ ‡: >99%)")
    print(f"ç‰ˆæœ¬å‡†ç¡®ç‡: {version_acc:.2%} (ç›®æ ‡: >95%)")
    
    assert family_acc > 0.99
    assert version_acc > 0.95
```

### 5.5 ç”Ÿäº§éƒ¨ç½²é¢„æ£€

```python
# tests/test_production_readiness.py

class TestProductionReadiness:
    """ç”Ÿäº§å°±ç»ªæ€§æ£€æŸ¥"""
    
    def test_api_documentation(self, client):
        """æ£€æŸ¥APIæ–‡æ¡£"""
        response = client.get("/docs")
        assert response.status_code == 200
        assert "swagger" in response.text.lower()
    
    def test_error_handling(self, client):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        response = client.post(
            "/api/v1/fingerprint/identify",
            json={"invalid": "data"}
        )
        assert response.status_code == 422  # éªŒè¯é”™è¯¯
    
    def test_health_endpoint(self, client):
        """å¥åº·æ£€æŸ¥"""
        response = client.get("/health")
        assert response.status_code == 200
        data = response.json()
        assert data['status'] == 'healthy'
    
    def test_logging(self, client):
        """æ—¥å¿—è®°å½•éªŒè¯"""
        # ç¡®ä¿æ‰€æœ‰æ“ä½œéƒ½è¢«è®°å½•
        response = client.post(
            "/api/v1/fingerprint/identify",
            json=SAMPLE_REQUEST
        )
        # æ£€æŸ¥æ—¥å¿—ä¸­æœ‰ç›¸å…³è®°å½•
        assert "æŒ‡çº¹è¯†åˆ«" in get_logs()
```

### 5.6 å·¥ä½œç»†èŠ‚

**æ–‡ä»¶æ¸…å•**:
- tests/test_integration.py (200è¡Œ)
- tests/test_performance.py (150è¡Œ)
- tests/test_accuracy.py (100è¡Œ)
- tests/test_production_readiness.py (80è¡Œ)

**æµ‹è¯•è¦†ç›–ç‡**:
- âœ“ é›†æˆæµ‹è¯• (ç«¯åˆ°ç«¯)
- âœ“ æ€§èƒ½åŸºå‡† (å»¶è¿Ÿ/ååé‡)
- âœ“ å‡†ç¡®ç‡éªŒè¯ (>95%)
- âœ“ ç”Ÿäº§å°±ç»ªæ£€æŸ¥

**é¢„æœŸäº§å‡º**:
- âœ“ 10ä¸ªä»¥ä¸Šæµ‹è¯•ç”¨ä¾‹
- âœ“ æ€§èƒ½åŸºå‡†æ•°æ®
- âœ“ 97%+ ä»£ç è¦†ç›–ç‡
- âœ“ ç”Ÿäº§éƒ¨ç½²å°±ç»ª

---

## æ—¶é—´è¡¨ä¸é‡Œç¨‹ç¢‘

```
Day 1 (2026-02-13):
  08:00 - 10:00   â†’ ä»»åŠ¡1: ç‰¹å¾æå–ç®¡é“ (2h)
  10:00 - 12:00   â†’ ä»»åŠ¡2: æ¨æ–­å¼•æ“ (2h)
  13:00 - 17:00   â†’ ä»»åŠ¡3: FastAPIæœåŠ¡ (4h)
  
Day 2 (2026-02-14):
  08:00 - 10:00   â†’ ä»»åŠ¡4: DockeråŒ– (2h)
  10:00 - 12:00   â†’ ä»»åŠ¡5: æµ‹è¯•ä¸éƒ¨ç½² (2h)
  12:00 - 12:30   â†’ æ–‡æ¡£å®Œæˆä¸äº¤æ¥
  
æ€»è®¡: 12å°æ—¶

å…³é”®é‡Œç¨‹ç¢‘:
  âœ“ 08:00 â†’ ç‰¹å¾ç®¡é“å°±ç»ª
  âœ“ 10:00 â†’ æ¨æ–­å¼•æ“å°±ç»ª
  âœ“ 12:00 â†’ APIæ¡†æ¶å°±ç»ª
  âœ“ 14:00 â†’ Dockerå®¹å™¨å°±ç»ª
  âœ“ 16:00 â†’ å®Œæ•´æµ‹è¯•é€šè¿‡
  âœ“ 17:00 â†’ ç”Ÿäº§éƒ¨ç½²å°±ç»ª
```

---

## éªŒæ”¶æ ‡å‡†

| ä»»åŠ¡ | å®Œæˆæ ‡å‡† | éªŒæ”¶æ–¹å¼ |
|------|---------|---------|
| **ç‰¹å¾æå–** | åº”ç”¨53ç»´ç‰¹å¾æ ‡å‡†åŒ– | å•å…ƒæµ‹è¯•è¦†ç›– |
| **æ¨æ–­å¼•æ“** | <2msæ¨æ–­å»¶è¿Ÿ | æ€§èƒ½åŸºå‡†æµ‹è¯• |
| **FastAPIæœåŠ¡** | 5ä¸ªç«¯ç‚¹ + Swaggeræ–‡æ¡£ | APIé›†æˆæµ‹è¯• |
| **DockeråŒ–** | é•œåƒ<200MB, å¯è¿è¡Œ | docker runæˆåŠŸ |
| **æµ‹è¯•** | ç²¾åº¦>95%, P99<50ms | smoke testsé€šè¿‡ |
| **éƒ¨ç½²** | å¯åœ¨Docker/K8sè¿è¡Œ | éƒ¨ç½²éªŒè¯ |

---

## é£é™©ä¸ç¼“è§£

| é£é™© | å½±å“ | ç¼“è§£æ–¹æ¡ˆ |
|------|------|----------|
| Pythonä¾èµ–å†²çª | æ„å»ºå¤±è´¥ | é”å®šä¾èµ–ç‰ˆæœ¬ (requirements.txt) |
| APIæ€§èƒ½ä¸è¶³ | æ¨æ–­è¶…è¿‡50ms | æ¨¡å‹ç¼“å­˜ + å¼‚æ­¥å¤„ç† |
| ç²¾åº¦ä¸‹é™ | é¢„æµ‹é”™è¯¯ | å®šæœŸé‡è®­ç»ƒ + ç›‘æ§ |
| Dockeré•œåƒè¿‡å¤§ | éƒ¨ç½²å›°éš¾ | å¤šé˜¶æ®µæ„å»º + å‹ç¼© |

---

## äº¤ä»˜ç‰©æ¸…å•

```
Phase 7.4 äº¤ä»˜:

ğŸ“¦ ä»£ç æ–‡ä»¶:
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py (FastAPIåº”ç”¨ä¸»æ–‡ä»¶)
â”‚   â”œâ”€â”€ routes.py (æ‰€æœ‰è·¯ç”±å®šä¹‰)
â”‚   â”œâ”€â”€ exceptions.py (å¼‚å¸¸å¤„ç†)
â”‚   â””â”€â”€ logging.py (æ—¥å¿—é…ç½®)
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ tls_features.py (TLSç‰¹å¾æå–)
â”‚   â”œâ”€â”€ http_features.py (HTTPç‰¹å¾æå–)
â”‚   â””â”€â”€ normalizer.py (ç‰¹å¾æ ‡å‡†åŒ–)
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ engine.py (æ¨æ–­å¼•æ“)
â”‚   â””â”€â”€ result.py (ç»“æœæ ¼å¼åŒ–)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ loader.py (æ¨¡å‹åŠ è½½å™¨)
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ models.py (Pydanticæ•°æ®æ¨¡å‹)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_integration.py
â”‚   â”œâ”€â”€ test_performance.py
â”‚   â”œâ”€â”€ test_accuracy.py
â”‚   â””â”€â”€ test_production_readiness.py
â””â”€â”€ Dockerfile + docker-compose.yml + requirements.txt

ğŸ“„ æ–‡æ¡£æ–‡ä»¶:
â”œâ”€â”€ docs/PHASE_7_4_API_SPECIFICATION.md
â”œâ”€â”€ docs/DEPLOYMENT_GUIDE.md
â”œâ”€â”€ API Swaggeræ–‡æ¡£ (è‡ªåŠ¨ç”Ÿæˆ)
â””â”€â”€ README.md (å¿«é€Ÿå¼€å§‹æŒ‡å—)

ğŸ³ Dockeré•œåƒ:
â””â”€â”€ fingerprint-api:1.0.0 (<200MB)

âœ… éªŒæ”¶æ ‡å‡†:
â”œâ”€â”€ ç‰¹å¾æå– (53ç»´, æ ‡å‡†åŒ–)
â”œâ”€â”€ æ¨æ–­å¼•æ“ (<2mså»¶è¿Ÿ)
â”œâ”€â”€ 5ä¸ªREST APIç«¯ç‚¹
â”œâ”€â”€ >95% ç²¾åº¦
â”œâ”€â”€ P99 <50ms
â””â”€â”€ ç”Ÿäº§å°±ç»ªæ£€æŸ¥é€šè¿‡
```

---

## åç»­ä¸Phase 8

**Phase 7.4å®Œæˆå**:

âœ… REST APIå®Œæ•´å¯ç”¨  
âœ… Dockerå®¹å™¨å¯éƒ¨ç½²  
âœ… OpenAPIæ–‡æ¡£å°±ç»ª  
âœ… ç²¾åº¦ä¸æ€§èƒ½éªŒè¯å®Œæˆ  

**Phase 8å±•æœ›** (åç»­å·¥ä½œ):

1. **ç”Ÿäº§ç›‘æ§**: æ·»åŠ PrometheusæŒ‡æ ‡
2. **å¤šç‰¹å¾èåˆ**: èåˆTCP/DNSæŒ‡çº¹ (å·²åœ¨Phase 6å®Œæˆ)
3. **æ ·æœ¬æ”¶é›†**: æŒç»­æ”¶é›†çœŸå®æµé‡æ ·æœ¬ä»¥æ”¹è¿›æ¨¡å‹
4. **æ€§èƒ½ä¼˜åŒ–**: ä½¿ç”¨ONNXæ ¼å¼åŠ é€Ÿæ¨æ–­
5. **æ‰©å±•åŠŸèƒ½**: å®ç°å®æ—¶æŒ‡çº¹æµå¼è¯†åˆ«

---

## æ€»ç»“

**Phase 7.4æ˜¯å°†Phase 7.1-7.3çš„ç ”ç©¶æˆæœè½¬åŒ–ä¸ºç”Ÿäº§çº§æœåŠ¡çš„å…³é”®æ­¥éª¤ã€‚**

é€šè¿‡12å°æ—¶çš„é›†ä¸­å¼€å‘:
- âœ… ä»MLæ¨¡å‹â†’REST API (ç‰¹å¾æå– + æ¨æ–­)
- âœ… å®Œæ•´çš„æœåŠ¡æ¡†æ¶ (FastAPI + Swagger)
- âœ… Dockerå®¹å™¨åŒ–éƒ¨ç½² (ä¸€é”®å¯åŠ¨)
- âœ… ç”Ÿäº§çº§æµ‹è¯•ä¸éªŒè¯
- âœ… æ–‡æ¡£ä¸è¿ç»´æ”¯æŒ

**é¢„æœŸäº§å‡º**: ä¸€ä¸ªå®Œæ•´çš„ã€å¯ç”Ÿäº§éƒ¨ç½²çš„ã€ç²¾åº¦>95%çš„æµè§ˆå™¨æŒ‡çº¹è¯†åˆ«æœåŠ¡ã€‚

