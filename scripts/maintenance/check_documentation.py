#!/usr/bin/env python3
"""
æ–‡æ¡£è´¨é‡è‡ªåŠ¨åŒ–æ£€æŸ¥å·¥å…·
ç”¨äºæ£€æŸ¥é¡¹ç›®æ–‡æ¡£çš„å®Œæ•´æ€§ã€ä¸€è‡´æ€§å’Œè´¨é‡
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Set, Tuple
from datetime import datetime

class DocumentationChecker:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.docs_dir = self.project_root / "docs"
        self.required_docs = {
            "æ ¸å¿ƒæ–‡æ¡£": [
                "README.md",
                "docs/INDEX.md",
                "PROJECT_STRUCTURE.md",
                "CONTRIBUTING.md"
            ],
            "ç”¨æˆ·æŒ‡å—": [
                "docs/user-guides/getting-started.md",
                "docs/user-guides/fingerprint-guide.md",
                "docs/user-guides/api-usage.md"
            ],
            "å¼€å‘è€…æŒ‡å—": [
                "docs/developer-guides/architecture.md",
                "docs/developer-guides/contributing.md"
            ]
        }
        
        self.quality_checks = [
            self.check_file_existence,
            self.check_links_validity,
            self.check_content_quality,
            self.check_naming_conventions,
            self.check_update_frequency
        ]

    def run_all_checks(self) -> Dict[str, any]:
        """è¿è¡Œæ‰€æœ‰æ–‡æ¡£æ£€æŸ¥"""
        results = {
            "timestamp": datetime.now().isoformat(),
            "summary": {},
            "details": {}
        }
        
        print("ğŸ” å¼€å§‹æ–‡æ¡£è´¨é‡æ£€æŸ¥...")
        
        # æ£€æŸ¥å¿…éœ€æ–‡æ¡£å­˜åœ¨æ€§
        existence_results = self.check_required_documents()
        results["details"]["existence"] = existence_results
        results["summary"]["missing_documents"] = len(existence_results.get("missing", []))
        
        # æ£€æŸ¥æ–‡æ¡£è´¨é‡
        quality_results = self.perform_quality_checks()
        results["details"]["quality"] = quality_results
        results["summary"]["quality_issues"] = sum(
            len(issues) for issues in quality_results.values()
        )
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(results)
        
        return results

    def check_required_documents(self) -> Dict[str, List[str]]:
        """æ£€æŸ¥å¿…éœ€æ–‡æ¡£æ˜¯å¦å­˜åœ¨"""
        missing = []
        present = []
        
        for category, docs in self.required_docs.items():
            for doc_path in docs:
                full_path = self.project_root / doc_path
                if full_path.exists():
                    present.append(doc_path)
                else:
                    missing.append(doc_path)
                    
        return {
            "present": present,
            "missing": missing
        }

    def perform_quality_checks(self) -> Dict[str, List[str]]:
        """æ‰§è¡Œæ–‡æ¡£è´¨é‡æ£€æŸ¥"""
        issues = {
            "broken_links": [],
            "outdated_content": [],
            "poor_structure": [],
            "missing_metadata": []
        }
        
        # éå†æ‰€æœ‰Markdownæ–‡ä»¶
        for md_file in self.project_root.rglob("*.md"):
            if "target/" in str(md_file) or ".git/" in str(md_file):
                continue
                
            try:
                content = md_file.read_text(encoding='utf-8')
                relative_path = md_file.relative_to(self.project_root)
                
                # æ£€æŸ¥æŸåçš„é“¾æ¥
                broken_links = self.find_broken_links(content, md_file)
                issues["broken_links"].extend([
                    f"{relative_path}: {link}" for link in broken_links
                ])
                
                # æ£€æŸ¥å†…å®¹è´¨é‡é—®é¢˜
                quality_issues = self.analyze_content_quality(content, relative_path)
                issues["poor_structure"].extend(quality_issues)
                
                # æ£€æŸ¥å…ƒæ•°æ®
                if not self.has_proper_metadata(content):
                    issues["missing_metadata"].append(str(relative_path))
                    
            except Exception as e:
                issues["broken_links"].append(f"{md_file}: è¯»å–é”™è¯¯ - {str(e)}")
        
        return issues

    def find_broken_links(self, content: str, file_path: Path) -> List[str]:
        """æŸ¥æ‰¾æŸåçš„é“¾æ¥"""
        broken_links = []
        
        # åŒ¹é…Markdowné“¾æ¥ [text](url)
        link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
        links = re.findall(link_pattern, content)
        
        for text, url in links:
            # è·³è¿‡å¤–éƒ¨é“¾æ¥å’Œé”šç‚¹
            if url.startswith(('http://', 'https://', '#', 'mailto:')):
                continue
                
            # æ£€æŸ¥ç›¸å¯¹é“¾æ¥
            if url.startswith('./') or url.startswith('../'):
                target_path = (file_path.parent / url).resolve()
            else:
                target_path = (self.project_root / url).resolve()
                
            if not target_path.exists():
                broken_links.append(f"æŸåé“¾æ¥: {url}")
                
        return broken_links

    def analyze_content_quality(self, content: str, file_path: Path) -> List[str]:
        """åˆ†æå†…å®¹è´¨é‡"""
        issues = []
        
        # æ£€æŸ¥æ ‡é¢˜ç»“æ„
        headings = re.findall(r'^(#{1,6})\s+(.+)$', content, re.MULTILINE)
        if len(headings) == 0:
            issues.append("ç¼ºå°‘æ ‡é¢˜ç»“æ„")
            
        # æ£€æŸ¥ä»£ç å—
        code_blocks = content.count('```')
        if code_blocks % 2 != 0:
            issues.append("æœªé—­åˆçš„ä»£ç å—")
            
        # æ£€æŸ¥åˆ—è¡¨æ ¼å¼
        list_items = re.findall(r'^(\s*)([-*+]|\d+\.)\s', content, re.MULTILINE)
        if list_items:
            # æ£€æŸ¥åµŒå¥—åˆ—è¡¨çš„ä¸€è‡´æ€§
            pass
            
        return issues

    def has_proper_metadata(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰é€‚å½“çš„å…ƒæ•°æ®"""
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ›´æ–°æ—¥æœŸ
        if not re.search(r'æœ€åæ›´æ–°[:\s]*20\d{2}', content):
            return False
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰ˆæœ¬ä¿¡æ¯
        if not re.search(r'ç‰ˆæœ¬[:\s]*v\d+\.\d+', content):
            return False
            
        return True

    def check_file_existence(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        return file_path.exists()

    def check_links_validity(self, content: str, file_path: Path) -> List[str]:
        """æ£€æŸ¥é“¾æ¥æœ‰æ•ˆæ€§"""
        return self.find_broken_links(content, file_path)

    def check_content_quality(self, content: str, file_path: Path) -> List[str]:
        """æ£€æŸ¥å†…å®¹è´¨é‡"""
        return self.analyze_content_quality(content, file_path)

    def check_naming_conventions(self, file_path: Path) -> bool:
        """æ£€æŸ¥å‘½åçº¦å®š"""
        filename = file_path.name.lower()
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨è‹±æ–‡å‘½å
        return bool(re.match(r'^[a-z0-9_-]+\.md$', filename))

    def check_update_frequency(self, file_path: Path) -> str:
        """æ£€æŸ¥æ›´æ–°é¢‘ç‡"""
        try:
            stat = file_path.stat()
            mtime = datetime.fromtimestamp(stat.st_mtime)
            days_since_update = (datetime.now() - mtime).days
            
            if days_since_update > 180:
                return "é•¿æœŸæœªæ›´æ–°"
            elif days_since_update > 90:
                return "è¾ƒé•¿æ—¶é—´æœªæ›´æ–°"
            else:
                return "è¿‘æœŸæ›´æ–°"
        except:
            return "æ— æ³•ç¡®å®š"

    def generate_report(self, results: Dict[str, any]):
        """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
        report_file = self.project_root / "output" / "reports" / "documentation_quality_report.md"
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# æ–‡æ¡£è´¨é‡æ£€æŸ¥æŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {results['timestamp']}\n\n")
            
            # æ‘˜è¦
            f.write("## ğŸ“Š æ£€æŸ¥æ‘˜è¦\n\n")
            f.write(f"- ç¼ºå¤±æ–‡æ¡£: {results['summary']['missing_documents']} ä¸ª\n")
            f.write(f"- è´¨é‡é—®é¢˜: {results['summary']['quality_issues']} ä¸ª\n\n")
            
            # è¯¦ç»†ç»“æœ
            f.write("## ğŸ“‹ è¯¦ç»†æ£€æŸ¥ç»“æœ\n\n")
            
            # å­˜åœ¨æ€§æ£€æŸ¥
            existence = results['details']['existence']
            f.write("### ğŸ“ æ–‡æ¡£å­˜åœ¨æ€§æ£€æŸ¥\n\n")
            if existence['missing']:
                f.write("**ç¼ºå¤±çš„æ–‡æ¡£**:\n")
                for doc in existence['missing']:
                    f.write(f"- `{doc}`\n")
                f.write("\n")
            
            # è´¨é‡æ£€æŸ¥
            quality = results['details']['quality']
            f.write("### ğŸ” æ–‡æ¡£è´¨é‡æ£€æŸ¥\n\n")
            
            for issue_type, issues in quality.items():
                if issues:
                    f.write(f"**{issue_type}**:\n")
                    for issue in issues[:10]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                        f.write(f"- {issue}\n")
                    if len(issues) > 10:
                        f.write(f"- ... è¿˜æœ‰ {len(issues) - 10} ä¸ªé—®é¢˜\n")
                    f.write("\n")

        print(f"âœ… æ£€æŸ¥æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

def main():
    checker = DocumentationChecker()
    results = checker.run_all_checks()
    
    # è¾“å‡ºç®€è¦ç»“æœ
    print(f"\nğŸ“‹ æ£€æŸ¥å®Œæˆ!")
    print(f"ğŸ“ ç¼ºå¤±æ–‡æ¡£: {results['summary']['missing_documents']} ä¸ª")
    print(f"ğŸ” è´¨é‡é—®é¢˜: {results['summary']['quality_issues']} ä¸ª")
    
    if results['summary']['missing_documents'] == 0 and results['summary']['quality_issues'] == 0:
        print("ğŸ‰ æ‰€æœ‰æ–‡æ¡£æ£€æŸ¥é€šè¿‡!")
    else:
        print("âš ï¸  å‘ç°æ–‡æ¡£é—®é¢˜ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Šã€‚")

if __name__ == "__main__":
    main()